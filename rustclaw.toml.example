# RustClaw Configuration Example
# 
# Config loading priority (highest to lowest):
# 1. Environment variables (TELEGRAM_BOT_TOKEN, OPENAI_API_KEY, etc.)
# 2. Local ./rustclaw.toml (workspace override)
# 3. Global ~/.rustclaw/rustclaw.toml (auto-created on first run)

[telegram]
bot_token = ""  # Set via TELEGRAM_BOT_TOKEN env var

[providers]
default = "openai"  # or "ollama"

[providers.openai]
api_key = ""  # Set via OPENAI_API_KEY env var
model = "gpt-4o-mini"
base_url = ""  # Optional: Set via OPENAI_BASE_URL env var

[providers.ollama]
base_url = "http://localhost:11434"
model = "llama3"

[agent]
# Maximum number of tool calls per request (prevents infinite loops)
max_tool_iterations = 10

# Context window size in tokens (for compression decisions)
context_window = 128000

# Number of recent conversation turns to keep before compression
recent_turns = 10

[database]
path = "rustclaw.db"

[logging]
level = "info"  # trace, debug, info, warn, error
