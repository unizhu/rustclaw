# RustClaw Configuration with MCP Example

[telegram]
bot_token = ""  # Set via TELEGRAM_BOT_TOKEN env var

[providers]
default = "openai"

[providers.openai]
api_key = ""  # Set via OPENAI_API_KEY env var
model = "gpt-4o-mini"

[agent]
max_tool_iterations = 10
context_window = 128000
recent_turns = 10

[database]
path = "rustclaw.db"

[logging]
level = "info"

# MCP Configuration
[mcp]
startup_timeout = 10  # Global default timeout in seconds

[mcp.servers]
# Filesystem MCP server (stdio transport)
filesystem = "npx -y @modelcontextprotocol/server-filesystem /tmp"

# GitHub MCP server (requires GITHUB_TOKEN env var)
# github = "mcp-server-github"

# HTTP-based MCP server (SSE transport)
# weather = "http://localhost:3000/sse"

# Skills Configuration
[skills]
# Directories to scan for skills (supports multiple)
# Skills are modular capabilities with progressive disclosure:
# - Phase 1: Metadata (name, description) loaded at startup
# - Phase 2: Full content loaded on-demand when matched
directories = ["~/.rustclaw/skills", "./.rustclaw/skills", "./examples/skills"]
