# RustClaw Configuration with MCP Example

[telegram]
bot_token = ""  # Set via TELEGRAM_BOT_TOKEN env var

[providers]
default = "openai"

[providers.openai]
api_key = ""  # Set via OPENAI_API_KEY env var
model = "gpt-4o-mini"

[agent]
max_tool_iterations = 10
context_window = 128000
recent_turns = 10

[database]
path = "rustclaw.db"

[logging]
level = "info"

# MCP Configuration
[mcp]
startup_timeout = 10  # Global default timeout in seconds

[mcp.servers]
# Filesystem MCP server (stdio transport)
filesystem = "npx -y @modelcontextprotocol/server-filesystem /tmp"

# GitHub MCP server (requires GITHUB_TOKEN env var)
# github = "mcp-server-github"

# HTTP-based MCP server (Streamable HTTP transport)
# weather = "http://localhost:3000/mcp"

# Remote MCP server with Bearer token auth
# [mcp.servers.web-search]
# url = "https://open.bigmodel.cn/api/mcp/web_search_prime/mcp"
# headers = { Authorization = "Bearer your_api_key" }

# Stdio MCP server with explicit args and environment variables
# [mcp.servers.zai-mcp-server]
# command = "npx"
# args = ["-y", "@z_ai/mcp-server"]
# env = { Z_AI_API_KEY = "your_api_key", Z_AI_MODE = "ZHIPU" }

# Skills Configuration
[skills]
# Directories to scan for skills (supports multiple)
# Skills are modular capabilities with progressive disclosure:
# - Phase 1: Metadata (name, description) loaded at startup
# - Phase 2: Full content loaded on-demand when matched
directories = ["~/.rustclaw/skills", "./.rustclaw/skills", "./examples/skills"]
